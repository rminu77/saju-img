# saju_image_app.py
# pip install streamlit google-genai pillow python-dotenv

import streamlit as st
from google import genai
from PIL import Image
from io import BytesIO
import time
import os
import base64
from dotenv import load_dotenv
import requests
from typing import Optional

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

load_dotenv()

st.set_page_config(page_title="ì‚¬ì£¼ â†’ ì´ë¯¸ì§€ ìƒì„±ê¸°", page_icon="ğŸ§§", layout="wide")

# ----------------------------
# ë¡œê·¸ì¸ ì²´í¬
# ----------------------------
def check_login():
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False

    if not st.session_state.logged_in:
        st.title("ğŸ” ë¡œê·¸ì¸")
        st.text_input("ID")
        password = st.text_input("PW", type="password")

        if st.button("ë¡œê·¸ì¸"):
            if password == "mateplan":
                st.session_state.logged_in = True
                st.rerun()
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

check_login()

# ----------------------------
# ì„¤ì •
# ----------------------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
TEXT_MODEL = "gemini-2.5-pro"                 # í”„ë¡¬í”„íŠ¸ ì‘ì„± ëª¨ë¸
IMAGE_MODEL = "gemini-2.5-flash-image-preview"  # ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸
OPENAI_TEXT_MODEL = "gpt-4.1"
OPENAI_IMAGE_MODEL = "gpt-image-1"
OPENAI_IMAGE_SIZE = "1024x1024"
DEFAULT_SYSTEM_INSTRUCTION = (
    "A mystical, hopeful scene rooted in Korean culture. "
    "Draw the characters in a way that highlights their personality, similar to Disney's Tangled and Encanto. "
    "The overall scene should be bright, rich in color, and vibrant, with a lovely emphasis on the characters. "
    "Express the faces in a Ghibli style. The lighting should be soft but powerful, and the characters should embody both warmth and vitality. "
    "The atmosphere should be both fantastical and dramatic."
)
DEFAULT_SUMMARY_INSTRUCTION = (
    "You are a Korean-to-English creative synthesis assistant with a warm, hopeful tone. "
    "Read the provided Korean saju text and create a vivid, single-scene description that can be rendered as one beautiful painting. "
    "Your description MUST include: "
    "1. WHO: A specific human figure (describe gender, youthful for their age, beautiful, and elegant appearance, attire, posture, must have no wrinkles) "
    "2. WHERE: A background that depicts the saju's contents "
    "3. WHAT: A specific action or gesture the person is performing in that moment "
    "The background must always be in Korea and include Korean cultural elements. Women wear a skirt hanbok, men wear pants hanbok.) "
    "ALWAYS center the description around the human figure - describe what the person looks like, what they are doing, and where they are. "
    "Portray the human figure as youthful for their age, beautiful, dignified, and elegant. "
    "Focus on positive, uplifting, and hopeful visual metaphors that inspire optimism and growth. "
    "Even when addressing challenges, frame them as opportunities for transformation and renewal. "
    "Emphasize bright colors, ascending movements, blooming elements, and harmonious compositions. "
    "Focus on concrete visual motifs and atmospheric cues that evoke hope and possibility. "
    "Create a description that an artist can immediately visualize and paint as a single, cohesive scene. "
    "Output the description in English as 1-2 sentences."
)

# ----------------------------
# ìœ í‹¸
# ----------------------------
def get_gemini_client():
    if not GEMINI_API_KEY:
        return None
    try:
        return genai.Client(api_key=GEMINI_API_KEY)
    except Exception:
        return None

def get_openai_client():
    if not OPENAI_API_KEY or not OpenAI:
        return None
    try:
        # httpx í´ë¼ì´ì–¸íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ í”„ë¡ì‹œ ë¬¸ì œ ìš°íšŒ
        # trust_env=Falseë¡œ í™˜ê²½ ë³€ìˆ˜ì˜ í”„ë¡ì‹œ ì„¤ì •ì„ ë¬´ì‹œ
        import httpx
        http_client = httpx.Client(trust_env=False)
        client = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)
        return client
    except ImportError:
        # httpxë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            return client
        except Exception as e:
            st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    except Exception as e:
        st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def summarize_for_visuals(
    source_text: str,
    provider: str = "gemini",
    gemini_client: Optional[genai.Client] = None,
    openai_client: Optional[OpenAI] = None,
    system_instruction: str = DEFAULT_SUMMARY_INSTRUCTION,
    openai_text_model: str = OPENAI_TEXT_MODEL,
) -> str:
    """
    ì‚¬ì£¼ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¼ì„ ìœ„í•œ 1~2ê°œì˜ í•µì‹¬ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.
    """
    user_msg = f"""
[SAJU TEXT / Korean]
{source_text}

[REQUEST]
- Summarize into one or two sentences highlighting visual motifs, elements, and atmosphere for illustration.
- Keep it concrete and metaphorical, avoid fortune-telling claims.
"""
    if provider == "openai":
        if not openai_client:
            raise ValueError("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        completion = openai_client.chat.completions.create(
            model=openai_text_model,
            messages=[
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": user_msg},
            ]
        )
        return (completion.choices[0].message.content or "").strip()

    if not gemini_client:
        raise ValueError("Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    resp = gemini_client.models.generate_content(
        model=TEXT_MODEL,
        contents=[system_instruction, user_msg]
    )
    return (resp.text or "").strip()

def write_prompt_from_saju(
    source_text: str,
    system_instruction: str = DEFAULT_SYSTEM_INSTRUCTION,
    provider: str = "gemini",
    gemini_client: Optional[genai.Client] = None,
    openai_client: Optional[OpenAI] = None,
    core_scene: Optional[str] = None,
    openai_text_model: str = OPENAI_TEXT_MODEL,
) -> str:
    """
    ì‚¬ì£¼ í…ìŠ¤íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì§€ì‹œì‚¬í•­ì„ ê²°í•©í•˜ì—¬ ì§ì ‘ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ë°˜í™˜
    """
    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œì‘
    prompt_parts = [system_instruction]

    # í•µì‹¬ ì¥ë©´ ì¶”ê°€
    if core_scene:
        prompt_parts.append(core_scene)

    # ëª¨ë“  ë¶€ë¶„ì„ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê²°í•©
    return " ".join(prompt_parts)

def generate_images(
    prompt: str,
    num_images: int = 3,
    provider: str = "gemini",
    gemini_client: Optional[genai.Client] = None,
    openai_client: Optional[OpenAI] = None,
):
    """
    í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±. ìµœëŒ€ num_imagesì¥ ì‹œë„.
    ë°˜í™˜: PIL.Image ë˜ëŠ” Noneì˜ ë¦¬ìŠ¤íŠ¸
    """
    images = []
    if provider == "openai":
        if not openai_client:
            return [None] * num_images
        for _ in range(num_images):
            try:
                response = openai_client.images.generate(
                    model=OPENAI_IMAGE_MODEL,
                    prompt=prompt,
                    size=OPENAI_IMAGE_SIZE,
                    n=1,
                )
                img_data = response.data[0] if response.data else None
                img_bytes = None
                if getattr(img_data, "b64_json", None):
                    img_bytes = base64.b64decode(img_data.b64_json)
                elif getattr(img_data, "url", None):
                    img_bytes = requests.get(img_data.url).content

                img = Image.open(BytesIO(img_bytes)).convert("RGBA") if img_bytes else None
                images.append(img)
            except Exception:
                images.append(None)
        return images

    if not gemini_client:
        return [None] * num_images

    for _ in range(num_images):
        try:
            response = gemini_client.models.generate_content(
                model=IMAGE_MODEL,
                contents=f"Create a picture of: {prompt}"
            )

            # google-genai ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
            img = None
            if getattr(response, "candidates", None):
                parts = response.candidates[0].content.parts
                for part in parts:
                    # part.inline_data.data ê°€ ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€
                    if getattr(part, "inline_data", None) and getattr(part.inline_data, "data", None):
                        data = part.inline_data.data
                        img = Image.open(BytesIO(data))
                        break
            images.append(img)
        except Exception:
            images.append(None)
    return images

# ----------------------------
# UI
# ----------------------------
st.title("ğŸ§§ ì‚¬ì£¼ í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€ ìƒì„±ê¸°")
st.caption("í”„ë¡¬í”„íŠ¸ ìƒì„±: gemini-2.0-flash Â· ì´ë¯¸ì§€ ìƒì„±: gemini-2.5-flash-image-preview (OpenAI ì˜µì…˜ ì§€ì›)")

gemini_client = get_gemini_client()
if GEMINI_API_KEY and not gemini_client:
    st.error("Google genai í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

openai_client = get_openai_client()
openai_available = bool(openai_client)

# ë””ë²„ê¹… ì •ë³´
st.write(f"DEBUG - OPENAI_API_KEY ì„¤ì • ì—¬ë¶€: {bool(OPENAI_API_KEY)}")
st.write(f"DEBUG - OpenAI íŒ¨í‚¤ì§€ import ì—¬ë¶€: {OpenAI is not None}")
st.write(f"DEBUG - openai_client ì´ˆê¸°í™” ì—¬ë¶€: {openai_client is not None}")
st.write(f"DEBUG - openai_available: {openai_available}")

if not gemini_client and not openai_available:
    st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEY ë˜ëŠ” OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

if "core_scene_summary" not in st.session_state:
    st.session_state.core_scene_summary = ""

if not GEMINI_API_KEY:
    st.info("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ OpenAI ì˜µì…˜ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
if not openai_available:
    st.info("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ openai íŒ¨í‚¤ì§€ê°€ ì—†ì–´ Google Gemini ì˜µì…˜ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

colA, colB = st.columns(2)
with colA:
    saju_meongsik = st.text_area("ì‚¬ì£¼ëª…ì‹", height=180, placeholder="ì˜ˆ) ê°‘ì åºšå­å¹´ ä¸™å¯…æœˆ å£¬åˆæ—¥ ä¹™å·³æ™‚ ...")
with colB:
    saju_puli = st.text_area("ì‚¬ì£¼í’€ì´", height=180, placeholder="ì˜ˆ) í™”(ç«) ê¸°ìš´ì´ ê°•í•˜ê³  ê¸ˆ/ìˆ˜ ë³´ì™„ì´ í•„ìš”â€¦ ë“± í•´ì„ ìš”ì•½")

system_prompt_input = st.text_area(
    "ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    value=DEFAULT_SYSTEM_INSTRUCTION,
    height=180,
    help="ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì‘ì„± ëª¨ë¸ì— ì „ë‹¬í•  ì‹œìŠ¤í…œ ë©”ì‹œì§€ì…ë‹ˆë‹¤.",
)
system_prompt = system_prompt_input if system_prompt_input.strip() else DEFAULT_SYSTEM_INSTRUCTION

summary_prompt_input = st.text_area(
    "ì¥ë©´ìš”ì•½ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
    value=DEFAULT_SUMMARY_INSTRUCTION,
    height=180,
    help="í•µì‹¬ ì¥ë©´ ìš”ì•½ ìƒì„± ëª¨ë¸ì— ì „ë‹¬í•  ì‹œìŠ¤í…œ ë©”ì‹œì§€ì…ë‹ˆë‹¤.",
)
summary_prompt = summary_prompt_input if summary_prompt_input.strip() else DEFAULT_SUMMARY_INSTRUCTION

model_col_1, model_col_2 = st.columns(2)
prompt_options = []
image_options = []
if gemini_client:
    prompt_options.append(("Google Gemini (gemini-2.5-pro)", ("gemini", "gemini-2.5-pro")))
    prompt_options.append(("Google Gemini (gemini-2.5-flash)", ("gemini", "gemini-2.5-flash")))
    image_options.append(("Google Gemini (gemini-2.5-flash-image-preview)", "gemini"))
if openai_available:
    prompt_options.append(("OpenAI GPT-4.1", ("openai", "gpt-4.1")))
    prompt_options.append(("OpenAI GPT-4.1-Mini", ("openai", "gpt-4.1-mini")))
    image_options.append(("OpenAI GPT-Image-1", "openai"))

with model_col_1:
    prompt_model_choice = st.selectbox(
        "í”„ë¡¬í”„íŠ¸ ëª¨ë¸ ì„ íƒ",
        options=[label for label, _ in prompt_options],
        index=0,
    )

prompt_provider, openai_text_model_selected = dict(prompt_options)[prompt_model_choice]
if prompt_provider != "openai":
    openai_text_model_selected = OPENAI_TEXT_MODEL

with model_col_2:
    image_model_choice = st.selectbox(
        "ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ",
        options=[label for label, _ in image_options],
        index=0,
    )

image_provider = dict(image_options)[image_model_choice]

mode = st.radio(
    "ìƒì„± ê¸°ì¤€ ì„ íƒ",
    ("ì‚¬ì£¼ëª…ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ë§Œë“¤ê¸°", "ì‚¬ì£¼í’€ì´ë¡œ ì´ë¯¸ì§€ ë§Œë“¤ê¸°"),
    horizontal=True
)

st.markdown("---")
generate = st.button("ğŸš€ ì´ë¯¸ì§€ ìƒì„±", type="primary", use_container_width=True)

if generate:
    if not saju_meongsik and not saju_puli:
        st.error("ì‚¬ì£¼ëª…ì‹ ë˜ëŠ” ì‚¬ì£¼í’€ì´ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    base_text = saju_meongsik if mode == "ì‚¬ì£¼ëª…ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ë§Œë“¤ê¸°" else saju_puli
    if not base_text.strip():
        st.error("ì„ íƒí•œ í•­ëª©ì˜ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    with st.spinner("ğŸ” í•µì‹¬ ì¥ë©´ ì¶”ì¶œ ì¤‘..."):
        try:
            core_scene = summarize_for_visuals(
                base_text,
                provider=prompt_provider,
                gemini_client=gemini_client,
                openai_client=openai_client,
                system_instruction=summary_prompt,
                openai_text_model=openai_text_model_selected,
            )
        except Exception as exc:
            st.error(f"í•µì‹¬ ì¥ë©´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            st.stop()
    core_scene = (core_scene or "").strip()
    st.session_state["core_scene_summary"] = core_scene
    if core_scene:
        st.markdown("#### âœ¨ í•µì‹¬ ì¥ë©´ ìš”ì•½")
        st.write(core_scene)

    with st.spinner("ğŸ“ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì¤‘..."):
        try:
            prompt = write_prompt_from_saju(
                base_text,
                system_instruction=system_prompt,
                provider=prompt_provider,
                gemini_client=gemini_client,
                openai_client=openai_client,
                core_scene=core_scene,
                openai_text_model=openai_text_model_selected,
            )
        except Exception as exc:
            st.error(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            st.stop()

    if not prompt:
        st.error("í”„ë¡¬í”„íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    final_prompt = prompt

    with st.spinner("ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
        imgs = generate_images(
            final_prompt,
            num_images=1,
            provider=image_provider,
            gemini_client=gemini_client,
            openai_client=openai_client,
        )

    valid = [i for i in imgs if i is not None]
    if valid:
        st.success(f"âœ… ì´ë¯¸ì§€ {len(valid)}ì¥ ìƒì„± ì™„ë£Œ!")
        st.markdown("### ìƒì„± ê²°ê³¼")
        cols = st.columns(3)
        for idx, im in enumerate(imgs):
            if im is None: 
                continue
            with cols[idx % 3]:
                st.image(im, caption=f"ìƒì„± ì´ë¯¸ì§€ #{idx+1}", use_container_width=True)
                buf = BytesIO()
                im.save(buf, format="PNG")
                st.download_button(
                    label=f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ #{idx+1}",
                    data=buf.getvalue(),
                    file_name=f"saju_generated_{int(time.time())}_{idx+1}.png",
                    mime="image/png",
                    key=f"dl_{idx}"
                )
    else:
        st.warning("ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ìˆ˜ì •í•´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if not generate:
    summary_display = st.session_state.get("core_scene_summary", "").strip()
    if summary_display:
        st.markdown("#### âœ¨ í•µì‹¬ ì¥ë©´ ìš”ì•½")
        st.write(summary_display)
